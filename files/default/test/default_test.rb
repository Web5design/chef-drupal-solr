require 'minitest/spec'
# minitest recipe
# Cookbook Name:: drupal-solr
# Spec:: default
#
include MiniTest::Chef::Assertions
include MiniTest::Chef::Context
include MiniTest::Chef::Resources

# Custom Tests:
class TestSolr < MiniTest::Chef::TestCase
  def test_tomcat
    tomcat_root_url = "http://localhost:#{node['tomcat']['port']}"
    command = "curl -I #{tomcat_root_url} | grep -q Apache-Coyote"
    txt = "curled #{tomcat_root_url} and expected an HTTP response from a Tomcat server"
    
    Chef::Log.info "curling #{tomcat_root_url}"
    assert_sh command , txt
  end
  def test_solr_server
    solr_ping_request = "http://localhost:#{node['tomcat']['port']}/" +
                        node['drupal-solr']['app_name'] +
                        "/admin/ping"
    command = "curl -I #{solr_ping_request} | grep OK"
    txt = "requested solr server at #{solr_ping_request} with a wildcard query"
    
    Chef::Log.info "curling #{solr_ping_request}"
    assert_sh command , txt
  end
  def test_drupal_solr_module
    command = "drush --root=#{node['drupal-solr']['drupal_root']} variable-get search_active_modules | grep apachesolr"
    txt = "expected to find apachesolr in active Drupal search modules"
    assert_sh command , txt
  end
  def test_drupal_solr_indexing 
    # number of automatically generated nodes for testing
    n = 2
    # assemble all necessary paths and urls
    mysql_root        = "mysql -u root -p#{node['drupal-solr']['mysql_root_pass']} " +
                        "--database=#{node['drupal-solr']['drupal_db']}"
    solr_root_url     = "http://localhost:#{node['tomcat']['port']}/" +
                        node['drupal-solr']['app_name']
    # this section is a ",' and \ mine field, watch yourself:
    # \&: since & in curl requests will confuse bash as background process indicator
    solr_commit_req   = solr_root_url + 
                        '/update?commit=true\&waitFlush=true\&waitSearcher=true'
    solr_luke_req     = solr_root_url + 
                        '/admin/luke?fl=numDocs\&wt=json'
    # the sed command should end up to be:
    # sed 's/^.*\"numDocs\":\([0-9]\{1,\}\).*$/\1/'
    find_num_docs     = "curl #{solr_luke_req} " +
                        '| sed \'s/^.*\"numDocs\":\([0-9]\{1,\}\).*$/\1/\''
    minitest_log_dir  = "/tmp/minitest/solr"
    drush             = "drush --root=#{node['drupal-solr']['drupal_root']}"
    
    system "rm -rf #{minitest_log_dir}; mkdir -p #{minitest_log_dir}"
    
    # install devel and enable devel and devel_generate if necessary 
    system "#{drush} download -n devel;\
            #{drush} pm-enable -y devel devel_generate;\
            #{drush} cache-clear all;"
    
    # record number of indexed documents in solr
    system "echo `#{find_num_docs}` > #{minitest_log_dir}/before"
    
    # make sure all existing documents are indexed and commited to solr
    system "#{drush} solr-index; curl #{solr_commit_req}"
    
    # generate content via drush, and record timestamps for cleanup
    before_time = Time.now.getutc.to_i
    system "#{drush} generate-content #{n} 0"
    after_time = Time.now.getutc.to_i
    
    # index new content, and send commit request to solr
    system "#{drush} solr-index; curl #{solr_commit_req}" 
    
    # record the number of indexed documents in solr after new content generation
    system "echo `#{find_num_docs}` > #{minitest_log_dir}/after"
    database_cleanup  = "#{mysql_root} -e \"\
                        DELETE FROM node WHERE \
                        created >= #{before_time} AND\
                        created < #{after_time}\""
    # cleanup the database: remove all nodes generated by drush genc
    # solr index is not cleaned up from drush genc garbage (solr-reindex is needed)
    system database_cleanup
    new_docs_cmd = "expr $(sed -n 1p #{minitest_log_dir}/after) - $(sed -n 1p #{minitest_log_dir}/before)"
    system "cat #{minitest_log_dir}/after; cat #{minitest_log_dir}/before"
    assert_sh "test `#{new_docs_cmd}` -eq #{n}" , "expected Solr to index new content"
  end
end
